# NavAssist
Advances in reinforcement learning have resulted in breakthroughs for algorithmic gameplay without yielding direct impact on the player experience. However, recent work has shown how to use game playing agents to directly power player assistance modes that improve the player experience. One avenue ripe for assist-mode support is 3D player navigation. For this support to be effective, we need both robust agents and also well-designed assistance methods. This need for an interdisciplinary approach makes it difficult for more specialized researchers to make progress in this new area. In this repot, we contribute the open-source _NavAssist_ research pipeline to bridge the gap between different disciplinary groups. 

We contribute several building blocks: 

(a) for reinforcement learning researchers,  OpenAI Gym compatible navigation environments to train more effective agents; 

(b) for game designers, a Unity game project and the pre-trained models to implement new AI-driven assistance methods;

(c) and for human-computer interaction researchers, a set of example assistance methods powered by pre-trained models to investigate  and evaluate  the effects of those assistance methods.


**Please include the submodule when cloning with ```git clone --recurse-submodules https://github.com/batu/NavAssist.git```**
